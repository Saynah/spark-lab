{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, we'll explore a few methods in Spark Core\n",
    "### Creating RDDs, collect(), map(), join(), reduceByKey(), aggregateByKey(), and filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll start with an online-dating dataset, described here: https://sites.google.com/a/insightdatascience.com/spark-lab/s3-data/dating-profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we create an RDD from a csv stored in s3, and use the collect() action, which returns an array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'10001,Tony',\n",
       " u'10002,Mike',\n",
       " u'10003,Pat',\n",
       " u'10004,Chris',\n",
       " u'10005,Paco',\n",
       " u'10006,Eddie',\n",
       " u'90001,Lisa',\n",
       " u'90002,Cindy',\n",
       " u'90003,Paula',\n",
       " u'90004,Leslie',\n",
       " u'90005,Allman',\n",
       " u'90006,Kimberly']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a csv of id, users\n",
    "rawUsersRDD = sc.textFile(\"s3n://insight-spark-after-dark/users-sm.csv\")\n",
    "rawUsersRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The collect action causes data to flow across the network from the worker nodes to the master (where you are running the jupyter notebook, or your data analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'10001,M',\n",
       " u'10002,M',\n",
       " u'10003,M',\n",
       " u'10004,M',\n",
       " u'10005,M',\n",
       " u'10006,M',\n",
       " u'90001,F',\n",
       " u'90002,F',\n",
       " u'90003,F',\n",
       " u'90004,F',\n",
       " u'90005,F',\n",
       " u'90006,F']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a csv of id, genders\n",
    "rawGendersRDD = sc.textFile(\"s3n://insight-spark-after-dark/gender-sm.csv\")\n",
    "rawGendersRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_tup(record):\n",
    "    tokens = record.split(\",\")\n",
    "    return (int(tokens[0]), str(tokens[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving toward a join action, we can use the map() method to create Key/Value pairs from the tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10001, 'Tony'),\n",
       " (10002, 'Mike'),\n",
       " (10003, 'Pat'),\n",
       " (10004, 'Chris'),\n",
       " (10005, 'Paco'),\n",
       " (10006, 'Eddie'),\n",
       " (90001, 'Lisa'),\n",
       " (90002, 'Cindy'),\n",
       " (90003, 'Paula'),\n",
       " (90004, 'Leslie'),\n",
       " (90005, 'Allman'),\n",
       " (90006, 'Kimberly')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usersRDD = rawUsersRDD.map(rec_tup)\n",
    "usersRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10001, 'M'),\n",
       " (10002, 'M'),\n",
       " (10003, 'M'),\n",
       " (10004, 'M'),\n",
       " (10005, 'M'),\n",
       " (10006, 'M'),\n",
       " (90001, 'F'),\n",
       " (90002, 'F'),\n",
       " (90003, 'F'),\n",
       " (90004, 'F'),\n",
       " (90005, 'F'),\n",
       " (90006, 'F')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gendersRDD = rawGendersRDD.map(rec_tup)\n",
    "gendersRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have two RDDs with Key/Value pairs, use the join method to join the RDDs based on the Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(90004, ('Leslie', 'F')),\n",
       " (10004, ('Chris', 'M')),\n",
       " (90005, ('Allman', 'F')),\n",
       " (90001, ('Lisa', 'F')),\n",
       " (10005, ('Paco', 'M')),\n",
       " (10001, ('Tony', 'M')),\n",
       " (90006, ('Kimberly', 'F')),\n",
       " (10002, ('Mike', 'M')),\n",
       " (90002, ('Cindy', 'F')),\n",
       " (10006, ('Eddie', 'M')),\n",
       " (10003, ('Pat', 'M')),\n",
       " (90003, ('Paula', 'F'))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usersWithGenderJoinedRDD = usersRDD.join(gendersRDD)\n",
    "usersWithGenderJoinedRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some further questions to get to grips with Spark basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: There exists another zipped csv, s3n://insight-spark-after-dark/gender.csv.gz. Create an RDD called genders_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Parse each of the record  from the genderRDDD so that we have a tuple of (gender(string), id(int)) and show \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Calculate the distribution of Males, Females, and Unknowns and show the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Calculate the sum of all the IDs for each gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Calculate the average of all the IDs for each gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Only return records from parsed_rdd which have ids that are a multiple of 5 and show the first 5 results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
