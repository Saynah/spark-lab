{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this tutorial we are going to look at performing joins in Spark and how to perform faster joins by minimizing data transfer between partitions.\n",
    "\n",
    "We are going to be using the dating profiles dataset for this tutorial. More information on this dataset can be found [here](https://sites.google.com/a/insightdatascience.com/spark-lab/s3-data/dating-profiles).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the data\n",
    "We need to specify 50 partitions for the gender table, otherwise will be loaded as a single partition. This dataset is rather small, so in order to see performance improvements with optimal Spark queries we are going to use the union transformation to 5x the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_raw = sc.textFile(\"s3n://insight-spark-after-dark/gender.csv.gz\").repartition(50)\n",
    "ratings_raw = sc.textFile(\"s3n://insight-spark-after-dark/ratings.csv.gz\")\\\n",
    "                .persist(StorageLevel.MEMORY_AND_DISK_SER)\n",
    "ratings_rep_raw = sc.emptyRDD()\n",
    "for i in range(5):\n",
    "    ratings_rep_raw = ratings_rep_raw.union(ratings_raw)\n",
    "    \n",
    "ratings_rep_raw = ratings_rep_raw.repartition(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_gender(row):\n",
    "    split_row = row.split(\",\")\n",
    "        \n",
    "    return (int(split_row[0]), split_row[1])\n",
    "\n",
    "def parse_ratings(row):\n",
    "    split_row = row.split(\",\")\n",
    "        \n",
    "    return (int(split_row[0]), int(split_row[1]), int(split_row[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will persist the parsed ratings and parsed gender using the cache() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_gender = gender_raw.map(parse_gender)\\\n",
    "                          .setName(\"gender\")\\\n",
    "                          .cache()\n",
    "parsed_ratings = ratings_rep_raw.map(parse_ratings).setName(\"ratings\").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing group by key and reduce by key\n",
    "\n",
    "## Are men more critical in ratings or the other way around?\n",
    "We are going to join the ratings table with the gender table on user id. Spark's join only works on key-value paired RDDs. We reorder our ratings RDD so each row is a tuple with the first element the user id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# are men more critical in ratings or the other way around?\n",
    "from_RDD = parsed_ratings.map(lambda r: (r[0], (r[1], r[2])))\n",
    "#from_RDD.sample(False, 0.001, 20).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the ratings with the gender table.\n",
    "\n",
    "Format of ratings table: **(userID, (profileID, rating) )**\n",
    "\n",
    "Format of gender table: **(userID, gender)**\n",
    "\n",
    "The output from the join: **(userID, ( (profileID, rating), gender_user) )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_from_RDD = from_RDD.join(parsed_gender)\n",
    "#joined_from_RDD.sample(False, 0.001, 20).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the **gender** for each **profileID** by joining the gender table on the **profileID**.\n",
    "\n",
    "First we want just **profileID**, **gender**, **rating** from the above join (dropping **userID** for speed) again organized as a key-value pair tuple for a join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tuple from join: (userID, ((profileID, rating), gender))\n",
    "to_RDD = joined_from_RDD.map(lambda r: (r[1][0][0], (r[1][1], r[1][0][1]))) # accessing profileID, gender, rating\n",
    "#to_RDD.sample(False, 0.001, 20).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then execute the join\n",
    "\n",
    "Format of to_RDD: **(profileID, (gender_user, rating) )**\n",
    "\n",
    "Format of gender table: **(userID, gender)**\n",
    "\n",
    "The output from the join: **(profileID, ( (gender_user, rating) gender_profile) )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_to_RDD = to_RDD.join(parsed_gender)\n",
    "#joined_to_RDD.sample(False, 0.001, 20).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the gender of the user, the gender of the profile and the rating. \n",
    "\n",
    "Map to the format: **( (gender_user, gender_profile) rating) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from_to_RDD = joined_to_RDD.map(lambda r: ((r[1][0][0], r[1][1]), r[1][0][1]))\\\n",
    "                           .setName(\"from_to\")\\\n",
    "                           .persist(StorageLevel.MEMORY_AND_DISK_SER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the format and the steps so far by looking at a sample (good practice).\n",
    "\n",
    "Use the sample transformation (with replacement = **False**, fraction of data = **0.001**, seed = **20**) and run the job by calling **collect()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from_to_RDD.sample(False, 0.001, 20).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping pairs of genders to find average rating per pair. \n",
    "\n",
    "### Naive approach: group by key. Let's time it to see performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "tot_cnt_RDD2 = from_to_RDD.groupByKey()\\\n",
    "                          .map(lambda r: (r[0], (sum(list(r[1]))/float(len(r[1])), len(r[1])))) # average, number\n",
    "print tot_cnt_RDD2.collect()\n",
    "end_time = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time for job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal approach: aggregate by key (reduce by key). \n",
    "\n",
    "Using an accumulator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "tot_cnt_RDD = from_to_RDD.aggregateByKey((0,0),\n",
    "                                         lambda acc, val: (acc[0]+val, acc[1]+1),\n",
    "                                         lambda acc1, acc2: (acc1[0]+acc2[0], acc1[1]+acc2[1]))\n",
    "avg_RDD = tot_cnt_RDD.mapValues(lambda r: (r[0]/float(r[1]), r[1])) # average, number\n",
    "\n",
    "print avg_RDD.collect()\n",
    "end_time = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time for job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The difference between job times is small here but for a big dataset this will be a huge difference.\n",
    "### Why is the second approach faster? \n",
    "Hint: check the 4040 while each of these approaches is running - in particular look at the specific stages associated with the job triggered by .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
